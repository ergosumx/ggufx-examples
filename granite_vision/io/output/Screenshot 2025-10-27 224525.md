
<doc> Nougat 
 \section{Title} we study the formula 
 \begin{equation} 
 E=mc^{2} 
 \label{einstein} 
 \end{equation} 
 as in \cite{ein} 
 a) tex 
 Figure 3: Data processing. 
 LaTeX source provided by t 
 Markdown file parsed from 
 4. Datasets 
 To the best of our knowledge, 
 created our own from the or- 
 Central 5 (PMC) open acces- 
 Library 6 (IDL) is included. 
 arXiv 
 We collected the 
 consistent formatting, we fin- 
 was important as it standard- 
 expressions. The conversion 
 brackets, normalizing tables. 
 We then parse the HTML file 
 such as headings, bold and 
 ensure that the source code is 
 The process is visualized in 
 PMC 
 We also processed 
 the PDF file. We parse these 
 articles from PMC because 
 tables are stored as images as 
 The XML files are parsed in 
 articles to the pre-training pl- 
 there is no paired dataset of PDF pages and corresponding scem access articles on arXiv.4 For layout diversity we also include non-commercial dataset. During the pretraining, a portion 
 Source code and compiled PDFs from 1,748,201 articles relate process the source files using LaTeXML7 and convert them inized and removed ambiguity from the LaTeX source code, process included replacing user-defined macros, standardizing and replacing references and citations with their correct num- 
 erics. See Table A.1 for the dataset composition. 
 erics from PMC, where XML files with semantic information 
 files into the same markup language format as the arXiv articles. The XML files are not always as rich in semantic information, and these cases are not trivial to detect, which leads to our decision 
 to the same markup language as described above. 
 source code out there, so we 
 de a subset of the PubMed 
 of the Industry Documents 
 based on arXiv. To ensure 
 to HTML5 files. This step 
 specially in mathematical 
 whitespace, adding optional 
 pers. 
 supports various elements 
 TeX tables. This way, we 
 are available in addition to 
 It. We chose to use far fewer 
 Often times equations and 
 on to limit the use of PMC 
 IDL 
 The IDL is a collect- 
 maintained by the University 
 mated IDL is a collect- 
 PDFs from the IDL dataset. 
 ociated with the University 
 4.1 Splitting the pages 
 maintained by the University 
 We split the markdown files 
 of public health and is 
 the final paired dataset. Du- 
 file into parts, which corresp- 
 and match it to source text. 
 erence. 
 4https://arxiv.org/ 
 5https://www.ncbi.nlm.nih.gov/ 
 6https://www.industrydocu- 
 7http://dlmf.nist.gov/LaTeX 
 ments.ucsf.edu/ 
 ML/ 
 4 
 act on public health and is 
 a high quality OCR text for 
 training to teach the model 
 page as an image to create 
 page breaks of the PDF file 
 ouristically split the source 
 added text on the PDF page 
 code. To address this issue, </doc>